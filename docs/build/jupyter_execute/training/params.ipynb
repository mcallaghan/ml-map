{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401884f7",
   "metadata": {},
   "source": [
    "# Optimizing hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06b757",
   "metadata": {
    "tags": [
     "remove-cell",
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4ef67",
   "metadata": {},
   "source": [
    "The model we have just trained works OK, but there are several choices we can make (beyond simply using the default parameters) about how the model should go about training. These choices, or **hyperparameters** will affect the performance of our model, in ways that we cannot always predict *a priori*. It is however likely that the default parameters are not the best ones.\n",
    "\n",
    "## Choosing parameters with huggingface\n",
    "\n",
    "We can set the parameters with a [TrainingArguments](https://huggingface.co/docs/transformers/v4.35.2/en/main_classes/trainer#transformers.TrainingArguments) object, which we then pass to our Trainer.\n",
    "\n",
    "The orignal BERT paper recommends we explore the following hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5984b",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"per_device_train_batch_size\": [16, 32],\n",
    "  \"learning_rate\": [5e-5, 3e-5, 2e-5],\n",
    "  \"num_train_epochs\": [2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65154466",
   "metadata": {},
   "source": [
    "We can turn this into a list of unique combinations using itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7226c",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def product_dict(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))\n",
    "param_list = list(product_dict(**params))\n",
    "print(len(param_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a86e11",
   "metadata": {
    "tags": [
     "thebe-init",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "glue('n_params', len(param_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0ae826",
   "metadata": {},
   "source": [
    "There are {glue:}`n_params` unique combinations of parameters in there. We'll first explore how we can test out one set.\n",
    "\n",
    "One thing we'll need to do is to separate a test set of documents from our training set. Our training procedure will not see these documents, and we'll see how well our model does at predicting the right values for documents it has not seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36c23f",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlmap import hf_tokenize_data, CustomTrainer\n",
    "df = pd.read_feather('data/labels.feather').sample(128, random_state=2023).reset_index(drop=True)\n",
    "df['text'] = df['title'] + ' ' + df['abstract']\n",
    "y_prefix = 'INCLUDE'\n",
    "targets = [x for x in df.columns if re.match(f'^{y_prefix}',x)]\n",
    "if len(targets)==1:\n",
    "    df['labels'] = df[targets[0]]\n",
    "    binary=True\n",
    "else:\n",
    "    df['labels'] = df[targets]\n",
    "    binary=False\n",
    "\n",
    "model_name = 'distilroberta-base'\n",
    "dataset = hf_tokenize_data(df, model_name)\n",
    "train_idx, test_idx = train_test_split(df.index)\n",
    "train_data = dataset.select(train_idx)\n",
    "test_data = dataset.select(test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e59eda",
   "metadata": {},
   "source": [
    "Now we have split our data up, we want to train a model with a given set of parameters on our training data, and test it on our testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b482a6",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, AutoModelForSequenceClassification, TrainingArguments\n",
    "p = param_list[0]\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    save_steps=1e9,\n",
    "    optim='adamw_torch'\n",
    ")\n",
    "for k, v in p.items():\n",
    "    setattr(training_args,k,v)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "trainer = CustomTrainer(model, train_dataset=train_data, args=training_args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1411c22a",
   "metadata": {},
   "source": [
    "Now we can see how well this work on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522570a",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "pred = trainer.predict_proba(test_data, binary=binary)\n",
    "\n",
    "y_true = df.loc[test_idx,'labels']\n",
    "glue('f1_p0', f1_score(y_true, pred.round()))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    pred.round(),\n",
    "    cmap='Blues'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df5381",
   "metadata": {},
   "source": [
    "This model achieved and f1 score of {glue:}`f1_p0`.\n",
    "\n",
    "## Class weighting\n",
    "\n",
    "The optimization procedure of our model penalizes mistaken classifications for all classes equally. Where we have unbalanced classes, this might mean our model gets good at predicting one common class at the expense of another less common class. This would not be ideal behaviour.\n",
    "\n",
    "We can penalize infrequent classes more heavily by calculating weights as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b8f82",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from torch import tensor, cuda, device\n",
    "device = \"cuda:0\" if cuda.is_available() else \"cpu\"\n",
    "weights = tensor(df.shape[0] / df[targets].sum(axis=0))\n",
    "weights = weights.to(device)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c411fe7b",
   "metadata": {},
   "source": [
    "We can subclass TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23ae66",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "from mlmap import CustomTrainingArguments\n",
    "\n",
    "training_args = CustomTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    save_steps=1e9,\n",
    "    optim='adamw_torch'\n",
    ")\n",
    "training_args.class_weights = weights\n",
    "training_args.use_class_weights = True\n",
    "for k, v in p.items():\n",
    "    setattr(training_args,k,v)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "trainer = CustomTrainer(model, train_dataset=train_data, args=training_args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25ea61",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": [
    "pred = trainer.predict_proba(test_data, binary=binary)\n",
    "\n",
    "y_true = df.loc[test_idx,'labels']\n",
    "glue('f1_p0c', f1_score(y_true, pred.round()))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_true,\n",
    "    pred.round(),\n",
    "    cmap='Blues'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bcd6a",
   "metadata": {},
   "source": [
    "This model achieved and f1 score of {glue:}`f1_p0c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504a5ae",
   "metadata": {
    "tags": [
     "thebe-init"
    ]
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.12,
    "jupytext_version": "1.8.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "execution_mode": "force",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   14,
   19,
   24,
   34,
   42,
   46,
   59,
   64,
   70,
   94,
   98,
   113,
   118,
   134,
   145,
   153,
   157,
   177,
   192,
   197
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}